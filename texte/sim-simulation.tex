\chapter{Simulations}

Simuler des images réalistes est un enjeu important en imagerie médicale. Le fait d'avoir accès à la vérité terrain, contrairement à la routine clinique, permet de valider des hypothèses de manière beaucoup plus fine. De plus, avec l'augmentation des performances de ordinateurs et l'accès à des centres de calculs, il devient possible de créer des bases de données de patients de plus en plus importantes et réalistes.

Nous allons tout d'abord présenter les différents types d'algorithme de simulations disponibles. Ensuite, nous feront un état de l'art des simulateurs développés par la communauté. Enfin, nous décrirons le simulateur retenu ainsi que les contributions réalisées pour générer la base de données.

	\section{principe des simulations}

		\subsection{Simulations analytiques}

Les simulateurs analytiques utilisent des approximations fortes pour résoudre les problèmes de manière analytique. Il ne simulent pas de manière réaliste le déplacement des particules (positon, photon) comme les simulateurs Monte-Carlo.

Dans le cas de l'imagerie TEP, la simulation analytique revient à réaliser des projections du volume TEP dans l'espace du sinogramme. Ce sinogramme est ensuite bruité et modifié pour prendre en compte les effets des coïncidences aléatoires et des photons diffusés. L'efficacité des détecteurs est aussi prise en compte, tout comme les effets de l'atténuation. 

La reconstruction est ensuite réalisée de manière classique à l'aide des algorithmes de reconstruction TEP.


Cependant, bien que ce type de simulateur soit extrêmement rapide, les images générées ne parviennent pas à reproduire de manière parfaite les différents phénomènes physiques à l'origine du bruit.




		\subsection{Simulation Monte Carlo}

Les simulations Monte-Carlo~\footnote{Le nom de Monte-Carlo fait allusion aux jeux de hasards pratiqués dans la ville du même nom} (MC) ont une approche probabiliste en modélisant la trajectoire de chaque photon indépendamment. .

Dans le cadre de l'imagerie TEP, le modèle probabiliste est appliqué à l'émission, puis au parcours du positon, à son annihilation, ainsi que les interactions et la probabilité de détection des photons dans les détecteurs.

La génération et le suivi de chaque photon ainsi que de chaque désintégration prennent un temps extrêmement important, amplifié par le fait que deux désintégrations successives dans des organes différents peuvent amener à une coïncidence fortuite. Il faut aussi prendre en compte les limitations de l'électronique (incapacité à séparer des évènements trop proches en temps comme en énergie, saturation des capteurs, \dots)ce qui amène à des temps de simulation prohibitifs de l'ordre de plusieurs mois, même sur des centres de calculs. Le grand Challenge TERA 10 crée en 2006 a mobilisé un supercalculateur comprenant 7000 processeurs pendant 3h pour simuler une image corps entier à l'aide du simulateur GATE, avant la mise en place des procédures d'accélérations. Cela revient à plus 10 jours de calculs ininterrompus pour une soumission sur centre de calculs avec 100 processeurs disponibles en permanence.

	\subsection{Simulation Monte Carlo accélérées}

Les simulateurs Monte-Carlo accélérés utilisent des heuristiques pour augmenter la vitesse des calculs, notamment en réalisant des calculs préliminaires afin de simplifier les simulations futures. 

La séparation des simulations entre les coïncidences directes et diffusées, à l’aide des statistiques créées précédemment, permet encore d’accélérer les calculs. Le projet ANR fGATE a permis une amélioration des temps de calculs d'un facteur 20 par rapport à ceux présentés ci-dessus.

	\section{\'Etat de l'art des simulateurs TEP}

De nombreux simulateurs ont été développés par la communauté. Ils sont souvent développés à partir d'une librairie dédiée aux calculs de trajectoires de particules, comme GATE~\cite{jan2004gate}, qui se base sur le jeu d'outils de simulation d'interactions particule/matière Geant4~\cite{allison2006geant4}, le simulateur Penelo-PET\cite{espana2009penelopet} basé sur la librairie de simulation  PENELOPE~\cite{salvat2006penelope}, ou encore EGS-PET. L’université de Washington développe le simulateur Monte Carlo simSET ainsi que le simulateur analytique ASIM. 

De très nombreux simulateurs ont été développés en interne par de petites équipes pour les besoins des laboratoires, mais ils s'oriente actuellement  vers GATE, qui bénéficie d'un développement rapide et d'une grande communauté.

Une étude décrit l'ensemble des codes disponibles en 2002~\cite{buvat2002monte}, et a été mise à jour en 2006~\cite{buvat2006monte} pour prendre en compte les avancées techniques réalisées.

Nous avons utilisé PET-SORTEO, car il a été développé pour augmenter la vitesse de simulations et profiter de la parallélisation offerte par les centres de calculs. De plus, nous avons réalisé à CREATIS la première version de la base de données OncoPET\_BD~\cite{tomei2010oncopet_db} sur ce simulateur, ce qui permet de capitaliser sur l’expérience déjà acquise. 

	\section{Processus de simulation avec SORTEO}
\label{lab:simuSORTEO}
Pour reproduire les données fournies par les systèmes cliniques TEP, les simulateurs Monte-Carlo simulent les désintégrations une par une et suivent les sous-produits dans les tissus jusqu'aux détecteurs. Étant donné qu'un examen TEP génère plusieurs millions de désintégrations, les temps de simulations deviennent très rapidement prohibitifs. PET-SORTEO dispose de plusieurs heuristiques qui permettent d'accélérer les simulations, notamment en séparant les simulations des différents types de coïncidences en fonction de statistiques estimées au début de la simulation. Cependant il faut tout de même encore plusieurs dizaines d'heures pour simuler une image correspondant à une acquisition clinique TEP corps entier au $^{18}$FGD.

a) Le logiciel prend en entrée deux cartes de labels voxelisées correspondant respectivement au type de traceur et à sa concentration (en $Bq/cm^3$), ainsi qu'à l'atténuation pour chaque voxel. A chaque label (nombre entier définissant une région) correspond un organe, qui peut être différent pour les deux cartes. Le type de scanner doit être précisé, ainsi que les paramètres d'acquisition (2D ou 3D), et le format de sortie (mode séquence ou sinogramme).

Toutes ces informations sont stockées dans un fichier texte, appellé fichier de protocole. Les cartes d'émission et d'atténuation voxeliques doivent être fournis au format ECAT (développé par Siemens).

b) Ensuite, la première partie de la simulation est utilisée pour déterminer un ensemble de probabilités permettant d'accélérer les calculs futurs. Pour cela, SORTEO réalise des simulations Monte Carlo complètes pour chaque label avec un faible nombre de photons. Cela permet de calculer plusieurs grandeurs telle que la probabilité de détection des photons pour chaque couple (label, détecteur) en prenant en compte les phénomènes physiques, ou encore la probabilité de détection en coïncidence des deux photons émis lors d'une désintégration pour chaque label.

c) La seconde partie de la simulation correspond à la réalisation de l'examen proprement dit. C'est à cette étape que sont simulées les coïncidences vraies, qu'elles soient diffusées ou non. Chaque coïncidence de chaque label est simulée une par une, et le trajet de chaque photon est calculé séparément. Si un des photons est absorbé ou si son énergie n'est pas dans la fenêtre énergétique déterminée par les paramètres d'acquision, alors la paire de photons est considérée comme perdue. Le programme passe à la désintégration suivante. \`A cette étape, le programme prend en compte les temps morts (limitation de l'électronique qui ne peut pas prendre en compte un trop grand nombre de photons en même temps), qui dépend de l'activité. Il est intéressant de noter que grâce aux statistiques estimées à la première étape, la trajectoire de certains photons n'est pas calculée car le simulateur considère qu'ils font partie des ``pertes``. C'est ce qui permet de réaliser les calculs très rapidement par rapport aux simulations Monte-Carlo classiques.

d) La dernière étape consiste à simuler les coïncidences aléatoires, qui sont ajoutées aux données précédentes. Ces dernières sont calculées à l'aide d'un modèle utilisant les paramètres mesurés à l'étape b), notamment le taux e photons simples arrivant sur chaque détecteur.


Le modèle utilisé par SORTEO est un compromis intéressant entre le réalisme apporté par les méthodes de Monte-Carlo et les performances apportées par les techniques de pré-calculs de statistiques ainsi que de séparation du calcul des coïncidences directes et fortuites. L'auteur de PET-SORTEO annonce que toutes les sources majeures de bruit et de biais sont prises en compte.

Le simulateur PET-SORTEO a été validé pour le simulateur Ecat Exact HR+~\cite{reilhac2004pet} ainsi que pour la plateforme PET Philips Allegro, qui est à la base du scanner TEP/TDM Gemini~\cite{lemaitre2008}. 


	\section{Contribution à PET-SORTEO}

Lors de ma thèse j'ai effectué plusieurs contributions au code de PET-SORTEO, notamment au niveau de la partie découpage des tâches pour l'exécution en centre de calcul, et au niveau de l'adaptation du programme aux données séquences.

\subsection{Adaptation pour l'exécution sur centre de calcul}

Le code original de SORTEO était adapté à une exécution sur des centres de calculs de petite taille, où la communication entre les processus n’est pas limitée. Cependant, étant donné les volumes de calculs représentés par nos simulations, nous avons fait appel au centre de calcul de l'in2p3 (Institut National de Physique Nucléaire et de Physique des Particules).

Ce centre de calcul regroupe plus de 1300 machines totalisant plus de 17000 cœurs, ainsi que 13 PetaOctets de stockage sur disques en 2011. Les technologies mises en places par les administrateur du centre de calcul sont spécialisées pour gérer cette quantité de données, ce qui représente des contraintes particulières quand aux techniques employées par les logiciels.

Par exemple, les différents processus du simulateur PET-SORTEO dialoguaient à travers des fichiers partagés. Cela engendrait des problèmes de saturation de la bande passante entre les nœuds. J'ai donc réalisé des modifications en profondeur du code pour séparer le simulateur en plusieurs entités, chacune réalisant une seule partie du travail :

    \begin{enumerate}
        \item Estimation des paramètres nécessaires à la simulation accélérée par simulation Monte-Carlo pur (lancé pour chaque processus).
        \item Combinaison des résultats Monte-Carlo.
        \item Simulation simplifiée des désintégrations (lancé pour chaque processus).
        \item Combinaison des désintégrations détectées pour chaque processus dans un seul fichier de données.
    \end{enumerate}

Ensuite, un ensemble de scripts a été réalisé pour automatiser les opérations de combinaison des résultats et de calcul des statistiques, puis pour relancer les simulations des coïncidences vraies et fortuites. Une dernière étape consiste à réassembler les détections pour générer les données séquence.

\subsection{Sortie en mode Séquence}

Bien que le code original permettait de spécifier un format de sortie, en pratique seul le format sinogramme était pris en compte. 

En effet, le code original ne permettait pas la sauvegarde de l'information temporelle de chaque évènement détecté. Or cette information est nécessaire aux méthodes de correction du mouvement respiratoire. 

Nous avons donc adapté PET-SORTEO au format séquence. Nous avons repris le format LMF développé lors de la collaboration CrystalClear pour générer les données, car ce format de données est simple à utiliser. Il se compose d'un fichier texte comprenant les informations sur l'acquisition ainsi que d'un fichier binaire contenant les évènements organisés de manière séquentiel.

 L'adaptation de SORTEO a nécessité entre autres ces adaptations :

\begin{itemize}
\item Intégrer la spécification du format de sortie dans le code.
\item Intégrer dans le code de PET-SORTEO des enregistreur d'évènements pour chaque désintégration détectée, car le code original se contentait de modifier un sinogramme. Cela a nécessité une modification en profondeur du code original.
\item Adapter la géométrie du modèle simulé pour correspondre aux conventions du LMF.
\item Ajouter une information temporelle non présente originellement à chaque évènement.
\item Réaliser le code permettant l'assemblage et le tri de toutes les émissions, qui sont réalisées séparément pour chaque organe.
\end{itemize}


%%%%%%%%%%%%%%% PARTIE RECONSTRUCTION ENVOYEE DANS METHODES
